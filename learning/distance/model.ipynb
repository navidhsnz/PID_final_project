{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "import os\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LaneDetectionCNN(nn.Module):\n",
    "    def __init__(self, input_shape):\n",
    "        super(LaneDetectionCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=2, padding=2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2, padding=2)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        # Calculate flat size dynamically\n",
    "        self._to_linear = None\n",
    "        self._calculate_flat_size(input_shape)\n",
    "\n",
    "        self.fc1 = nn.Linear(self._to_linear, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)  # Single output neuron for regression\n",
    "\n",
    "    def _calculate_flat_size(self, input_shape):\n",
    "        x = torch.zeros(1, *input_shape)\n",
    "        x = self._forward_conv(x)\n",
    "        self._to_linear = x.numel()\n",
    "\n",
    "    def _forward_conv(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.relu(self.conv3(x))\n",
    "        x = torch.relu(self.conv4(x))\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self._forward_conv(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.tanh(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "# Training function\n",
    "def train_model(model, dataloader, criterion, optimizer, n_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(n_epochs):\n",
    "        total_loss = 0\n",
    "        for Xbatch, ybatch in dataloader:\n",
    "            # Move inputs and labels to device\n",
    "            Xbatch, ybatch = Xbatch.to(device), ybatch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(Xbatch)\n",
    "            loss = criterion(y_pred, ybatch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{n_epochs}, Loss: {total_loss/len(dataloader):.4f}\")\n",
    "        \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, image_folder, label_folder, transform=None):\n",
    "        self.image_folder = image_folder\n",
    "        self.label_folder = label_folder\n",
    "        self.transform = transform\n",
    "        self.image_files = sorted(os.listdir(image_folder))  # Ensure consistent order\n",
    "        self.label_files = sorted(os.listdir(label_folder))  # Ensure consistent order\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        img_path = os.path.join(self.image_folder, self.image_files[idx])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Load corresponding label\n",
    "        label_path = os.path.join(self.label_folder, self.label_files[idx])\n",
    "        with open(label_path, \"r\") as f:\n",
    "            label = float(f.read().strip())  # Read distance as float\n",
    "\n",
    "        return image, torch.tensor([label], dtype=torch.float32)\n",
    "\n",
    "def get_dataloader(image_folder, label_folder, batch_size):\n",
    "    \"\"\"\n",
    "    Create a DataLoader for the dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - image_folder: Path to the folder containing images.\n",
    "    - label_folder: Path to the folder containing labels.\n",
    "    - batch_size: Batch size for the DataLoader.\n",
    "    - input_shape: Tuple (height, width) for resizing images.\n",
    "\n",
    "    Returns:\n",
    "    - DataLoader object for training.\n",
    "    \"\"\"\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),  # Convert to tensor without resizing\n",
    "    ])\n",
    "\n",
    "    dataset = ImageDataset(image_folder, label_folder, transform=transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "def get_input_shape(image_folder):\n",
    "    \"\"\"\n",
    "    Dynamically determine the input shape from the first image in the dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - image_folder: Path to the folder containing images.\n",
    "\n",
    "    Returns:\n",
    "    - Tuple representing the input shape (channels, height, width).\n",
    "    \"\"\"\n",
    "    # Get the first image in the folder\n",
    "    image_files = sorted(os.listdir(image_folder))\n",
    "    if not image_files:\n",
    "        raise ValueError(f\"No images found in folder: {image_folder}\")\n",
    "\n",
    "    # Load the first image\n",
    "    img_path = os.path.join(image_folder, image_files[0])\n",
    "    with Image.open(img_path) as img:\n",
    "        width, height = img.size  # Image dimensions\n",
    "        channels = len(img.getbands())  # Number of color channels (e.g., RGB = 3)\n",
    "\n",
    "    return (channels, height, width)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Determined input shape: (3, 480, 640)\n",
      "Number of images in the dataset: 4000\n",
      "Epoch 1/5, Loss: 0.0006\n",
      "Epoch 2/5, Loss: 0.0003\n",
      "Epoch 3/5, Loss: 0.0005\n",
      "Epoch 4/5, Loss: 0.0003\n",
      "Epoch 5/5, Loss: 0.0003\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "    IMAGE_FOLDER = \"road_images/trail1/images\"\n",
    "    LABEL_FOLDER = \"road_images/trail1/labels\"\n",
    "    batch_size = 16\n",
    "\n",
    "    input_shape = get_input_shape(image_folder=IMAGE_FOLDER)\n",
    "    print(f\"Determined input shape: {input_shape}\")\n",
    "\n",
    "\n",
    "    dataloader = get_dataloader(IMAGE_FOLDER, LABEL_FOLDER, batch_size)\n",
    "\n",
    "    num_images = len(dataloader.dataset)\n",
    "    print(f\"Number of images in the dataset: {num_images}\")\n",
    "\n",
    "\n",
    "    model = LaneDetectionCNN(input_shape).to(device)\n",
    "\n",
    "    criterion = nn.MSELoss()  # Mean Squared Error Loss for regression\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Train the model\n",
    "    train_model(model, dataloader, criterion, optimizer, n_epochs=5)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ## notes: \n",
    "    ## to display an image: \n",
    "\n",
    "    # for Xbatch, ybatch in dataloader:\n",
    "    #     sample = Xbatch[0]\n",
    "    #     image_array = (sample.permute(1, 2, 0).numpy() * 255).astype(\"uint8\")\n",
    "    #     print(type(image_array))  \n",
    "    #     image = Image.fromarray(image_array)\n",
    "    #     image.show()\n",
    "    #     break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights saved to 'lane_detection_model.pth'\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"lane_detection_model.pth\")\n",
    "print(\"Model weights saved to 'lane_detection_model.pth'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights loaded from 'lane_detection_model.pth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_191433/563164654.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"lane_detection_model.pth\"))\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model architecture\n",
    "model = LaneDetectionCNN((3, 480, 640))\n",
    "\n",
    "# Load the model weights\n",
    "model.load_state_dict(torch.load(\"lane_detection_model.pth\"))\n",
    "model.eval()  # Set to evaluation mode\n",
    "print(\"Model weights loaded from 'lane_detection_model.pth'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "for Xbatch, ybatch in dataloader:\n",
    "    sample = Xbatch[0]\n",
    "    image_array = (sample.permute(1, 2, 0).numpy() * 255).astype(\"uint8\")\n",
    "    print(type(image_array))  \n",
    "    image_bgr = cv2.cvtColor(image_array, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    cv2.imshow(\"Image\", image_bgr)\n",
    "    cv2.waitKey(0)  # Wait for a key press\n",
    "    cv2.destroyAllWindows()\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Random Image Test:\n",
      "  Predicted Distance: 0.11742646992206573\n",
      "  Actual Distance: 0.12933236360549927\n",
      "Random Image Test:\n",
      "  Predicted Distance: 0.0947289988398552\n",
      "  Actual Distance: 0.10634204745292664\n",
      "Random Image Test:\n",
      "  Predicted Distance: -0.07368995994329453\n",
      "  Actual Distance: -0.04290331155061722\n",
      "Random Image Test:\n",
      "  Predicted Distance: 0.09768050909042358\n",
      "  Actual Distance: 0.0975923240184784\n",
      "Random Image Test:\n",
      "  Predicted Distance: 0.02450891025364399\n",
      "  Actual Distance: 0.03243619576096535\n",
      "Random Image Test:\n",
      "  Predicted Distance: -0.047557760030031204\n",
      "  Actual Distance: -0.033719055354595184\n",
      "Random Image Test:\n",
      "  Predicted Distance: -0.037635453045368195\n",
      "  Actual Distance: -0.03818884491920471\n",
      "Random Image Test:\n",
      "  Predicted Distance: 0.04547379910945892\n",
      "  Actual Distance: 0.051262252032756805\n",
      "Random Image Test:\n",
      "  Predicted Distance: 0.12966281175613403\n",
      "  Actual Distance: 0.138238787651062\n",
      "Random Image Test:\n",
      "  Predicted Distance: 0.005380312446504831\n",
      "  Actual Distance: 0.00904418621212244\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def test_model(model, dataloader, device):\n",
    "    \"\"\"\n",
    "    Test the trained model on a random image from the dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - model: The trained neural network model.\n",
    "    - dataloader: The DataLoader providing the test data.\n",
    "    - device: The device to use for prediction ('cpu' or 'cuda').\n",
    "\n",
    "    Returns:\n",
    "    - Tuple containing the predicted distance and the actual label.\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    # Choose a random batch and image\n",
    "    random_idx = random.randint(0, len(dataloader.dataset) - 1)\n",
    "    image_tensor, label_tensor = dataloader.dataset[random_idx]\n",
    "\n",
    "    # Move image tensor and label to device\n",
    "    image_tensor = image_tensor.to(device).unsqueeze(0)  # Add batch dimension\n",
    "    label_tensor = label_tensor.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        prediction = model(image_tensor)  # Predict the distance\n",
    "\n",
    "    predicted_distance = prediction.item()\n",
    "    actual_label = label_tensor.item()\n",
    "\n",
    "    print(f\"Random Image Test:\")\n",
    "    print(f\"  Predicted Distance: {predicted_distance}\")\n",
    "    print(f\"  Actual Distance: {actual_label}\")\n",
    "\n",
    "    image_array = (image_tensor[0].cpu().permute(1, 2, 0).numpy() * 255).astype(\"uint8\")\n",
    "    image_bgr = cv2.cvtColor(image_array, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    cv2.imshow(\"Image\", image_bgr)\n",
    "    cv2.waitKey(0)  # Wait for a key press\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return predicted_distance, actual_label\n",
    "\n",
    "\n",
    "\n",
    "IMAGE_FOLDER = \"road_images/trail1/images\"\n",
    "LABEL_FOLDER = \"road_images/trail1/labels\"\n",
    "batch_size = 16\n",
    "dataloader = get_dataloader(IMAGE_FOLDER, LABEL_FOLDER, batch_size)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "for _ in range(10):\n",
    "    predicted_distance, actual_label = test_model(model, dataloader, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
